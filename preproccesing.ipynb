{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091da14c-9b1c-49e7-bbb2-d9ca627725e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e793a1-ed28-46a0-9c55-513e2f9fe5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bu fonksiyon bizim spectrogram dosyalarımızdan datasetlerini oluşturmamızı sağlar.\n",
    "def get_data(file_path,IMG_SIZE):\n",
    "    data = []\n",
    "    for i in file_path:\n",
    "        for img in os.listdir(i):\n",
    "            #Resim dosyasını okuyup numpy array tipine dönüştürüyoruz.\n",
    "            image=cv2.imread(str(i)+\"\\\\\"+str(img),1)\n",
    "            #Resim dosyasını yeniden boyutlandırıyoruz.\n",
    "            image=cv2.resize(image,(IMG_SIZE,IMG_SIZE))\n",
    "            #Normalizasyon işlemi yapıyoruz.\n",
    "            image=np.float32(image)\n",
    "            image/=255.0\n",
    "            #Resim dizisini yeniden boyutlandırıyoruz.\n",
    "            image = image.reshape((IMG_SIZE, IMG_SIZE, 3))\n",
    "            #GrayScale işlemini yapıyoruz.\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            #Resim dizisini ve ait olduğu sınıfı data listesine ekliyoruz.\n",
    "            data.append([image,int(img.split(\"-\")[1])])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82837d11-762a-411c-9166-2040ab3885e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "file_path = glob.glob('spectrograms/*')\n",
    "\n",
    "#Dataseti oluşturuyoruz.\n",
    "data = get_data(file_path, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3713c087-bb21-4a0c-aff1-945b972d4dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8732"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29109b58-2131-42dc-84ec-8abf1b2b4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verilerin karışık sıralarda tutulması için karma işlemi yapıyoruz.\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1474da-393a-4d7e-a9e4-183fd91e4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Girdi ve çıktıların ayrı listelerde olmasını sağlıyoruz.\n",
    "def getIO(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in data:\n",
    "        X.append(i[0])\n",
    "        y.append(i[1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1b65b3-66e6-4e1d-878e-081f08546774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = getIO(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d384db35-4454-44eb-9920-82f0f6064f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İlk olarak train datasetleri oluşturuyoruz. Ardından validation ve test için temporary değişkenlerini tutuyoruz.\n",
    "X_train , X_temporary , y_train , y_temporary = train_test_split(X,y,train_size = 0.8, shuffle=False)\n",
    "\n",
    "# Temporary değişkenlerinden validation ve test datasetlerini oluşturuyoruz.\n",
    "X_val , X_test , y_val , y_test = train_test_split(X_temporary,y_temporary,train_size = 0.5, shuffle=False)\n",
    "\n",
    "#Shuffle değişkenini False seçme sebebimiz, daha önceden bu işlemi yapmış olmamızdı. Zaten shuffle True olsaydı I/O değerleri yanlış olacaktı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7425eb23-1ad5-40aa-a1d8-f42ff4c21752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset len: 8732\n",
      "Train len: 6985\n",
      "Validation len: 873\n",
      "Test len: 874\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset len:\",len(X))\n",
    "print(\"Train len:\",len(X_train))\n",
    "print(\"Validation len:\",len(X_val))\n",
    "print(\"Test len:\",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdae972-1b40-4e6c-af33-90455126ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kayıt başarılı!\n"
     ]
    }
   ],
   "source": [
    "#verileri kaydediyoruz.\n",
    "with open(\"dataset\",\"wb\") as f:\n",
    "    pickle.dump([X_train, y_train, X_val, y_val, X_test, y_test], f)\n",
    "    print(\"kayıt başarılı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627c42c-0d36-4c11-83ef-0d3ef8cfc8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
